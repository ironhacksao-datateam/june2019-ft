{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reduce from functools, numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun fact: \n",
    "In 2005, the Python's language author Guido van van Rossum expressed his critics about map(), filter(), and reduce(). He advocated agaist those functions, affirming that loops were more legible and easy to handle. The discussion reached a point of excluding reduce from build-in function, isolating reduce into the functools library.\n",
    "\n",
    "Source: https://www.artima.com/weblogs/viewpost.jsp?thread=98196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up some words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Kahlil Gibran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The book could be downloaded via the this [website](https://www.gutenberg.org/ebooks/58585).\n",
    "* Our first step is download the data and open it in our Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory location\n",
    "location = '../58585-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file using the open()\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: <class 'str'>\n",
      "Object length: 87749\n"
     ]
    }
   ],
   "source": [
    "# the object imported is a string\n",
    "print('Object type:', type(prophet_string))\n",
    "print('Object length:', len(prophet_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, let's divide the string object we just imported based on the space character;\n",
    "* The method that 'divide' the string is called split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split/ divide/ tokenize the objected with the method split()\n",
    "prophet = prophet_string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type: <class 'list'>\n",
      "Object length: 13637\n"
     ]
    }
   ],
   "source": [
    "# after split the string, it will return a list with 13.637 elements\n",
    "print('Object type:', type(prophet))\n",
    "print('Object length:', len(prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you explain the reason why the type of the element has changed and the number of elements decreased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the elements represented characters, all the letters in the string\n",
    "#after split the number of elements represent the number of wordds in the string\n",
    "#after split each word became a separate string in a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13637\n"
     ]
    }
   ],
   "source": [
    "# Let's start by checking the number of elements inside the list 'prophet'\n",
    "print(len(prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The length of all prophet elements is 13.637. If we drop the first 568 elements, we're expecting to create a new one with 13.069 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13069"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prophet)-568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Method 1__: just to keep in mind the string slide method using [ ]\n",
    "* Now let's slice the data from 568 until the index '13637', or the list length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the max list's size\n",
    "max_size = 568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with a the list object followed by a bracket\n",
    "prophet_568 = prophet[\n",
    "    # define the max size\n",
    "    max_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13069"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new object's len is 568 elements, as we have expected\n",
    "len(prophet_568)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recheck: the element indexed as 568 is 'PROPHET\\n\\n|Almustafa,'.\n",
    "* And so, the new object should start with the same element 'PROPHET\\n\\n|Almustafa,'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPHET\\n\\n|Almustafa,'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet[568]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPHET\\n\\n|Almustafa,'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_568[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the string from index 1 to 10\n",
    "prophet1_10 = prophet[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nThis']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet1_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the new element lenghts 9 elements\n",
    "len(prophet1_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    # Your code here:\n",
    "    return x.split('{')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_string.index('{')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's check where the '{' is inside our string -- the one we have imported fist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_reference = list(map(reference, prophet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nThis',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and\\nmost',\n",
       " 'other',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions\\nwhatsoever.',\n",
       " '',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms\\nof',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at\\nwww.gutenberg.org.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'located',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " \"you'll\\nhave\",\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'where',\n",
       " 'you',\n",
       " 'are',\n",
       " 'located',\n",
       " 'before',\n",
       " 'using\\nthis',\n",
       " 'ebook.\\n\\n\\n\\nTitle:',\n",
       " 'The',\n",
       " 'Prophet\\n\\nAuthor:',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nRelease',\n",
       " 'Date:',\n",
       " 'January',\n",
       " '1,',\n",
       " '2019',\n",
       " '[EBook',\n",
       " '#58585]\\nLast',\n",
       " 'Updated:',\n",
       " 'January',\n",
       " '3,',\n",
       " '2018\\n\\n\\nLanguage:',\n",
       " 'English\\n\\nCharacter',\n",
       " 'set',\n",
       " 'encoding:',\n",
       " 'UTF-8\\n\\n***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'THE',\n",
       " 'PROPHET',\n",
       " '***\\n\\n\\n\\n\\nProduced',\n",
       " 'by',\n",
       " 'David',\n",
       " 'Widger',\n",
       " 'from',\n",
       " 'page',\n",
       " 'images',\n",
       " 'generously\\nprovided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Internet',\n",
       " \"Archive\\n\\n\\nTranscriber's\",\n",
       " 'Note:',\n",
       " 'Page',\n",
       " 'numbers,',\n",
       " 'ie:',\n",
       " '',\n",
       " 'are',\n",
       " 'included',\n",
       " 'in',\n",
       " 'this\\nutf-8',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'For',\n",
       " 'those',\n",
       " 'wishing',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'text',\n",
       " 'file',\n",
       " 'unencumbered\\nwith',\n",
       " 'page',\n",
       " 'numbers',\n",
       " 'open',\n",
       " 'or',\n",
       " 'download',\n",
       " 'the',\n",
       " 'Latin-1',\n",
       " 'file',\n",
       " '58585-8.txt.\\n\\n\\n\\n\\n\\n\\n\\nTHE',\n",
       " 'PROPHET\\n\\nBy',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nNew',\n",
       " 'York:',\n",
       " 'Alfred',\n",
       " 'A.',\n",
       " 'Knopf\\n\\n1923\\n\\n_The',\n",
       " 'Twelve',\n",
       " 'Illustrations',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Volume\\nAre',\n",
       " 'Reproduced',\n",
       " 'From',\n",
       " 'Original',\n",
       " 'Drawings',\n",
       " 'By\\nThe',\n",
       " 'Author_\\n\\n\\n“His',\n",
       " 'power',\n",
       " 'came',\n",
       " 'from',\n",
       " 'some',\n",
       " 'great',\n",
       " 'reservoir\\nof',\n",
       " 'spiritual',\n",
       " 'life',\n",
       " 'else',\n",
       " 'it',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have\\nbeen',\n",
       " 'so',\n",
       " 'universal',\n",
       " 'and',\n",
       " 'so',\n",
       " 'potent,',\n",
       " 'but',\n",
       " 'the\\nmajesty',\n",
       " 'and',\n",
       " 'beauty',\n",
       " 'of',\n",
       " 'the',\n",
       " 'language',\n",
       " 'with\\nwhich',\n",
       " 'he',\n",
       " 'clothed',\n",
       " 'it',\n",
       " 'were',\n",
       " 'all',\n",
       " 'his',\n",
       " 'own?”\\n\\n--Claude',\n",
       " 'Bragdon\\n\\n\\nTHE',\n",
       " 'BOOKS',\n",
       " 'OF',\n",
       " 'KAHLIL',\n",
       " 'GIBRAN\\n\\nThe',\n",
       " 'Madman.',\n",
       " '1918',\n",
       " 'Twenty',\n",
       " 'Drawings.',\n",
       " '1919\\nThe',\n",
       " 'Forerunner.',\n",
       " '1920',\n",
       " 'The',\n",
       " 'Prophet.',\n",
       " '1923\\nSand',\n",
       " 'and',\n",
       " 'Foam.',\n",
       " '1926',\n",
       " 'Jesus',\n",
       " 'the',\n",
       " 'Son',\n",
       " 'of\\nMan.',\n",
       " '1928',\n",
       " 'The',\n",
       " 'Forth',\n",
       " 'Gods.',\n",
       " '1931',\n",
       " 'The\\nWanderer.',\n",
       " '1932',\n",
       " 'The',\n",
       " 'Garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Prophet\\n1933',\n",
       " 'Prose',\n",
       " 'Poems.',\n",
       " '1934',\n",
       " 'Nymphs',\n",
       " 'of',\n",
       " 'the\\nValley.',\n",
       " '1948\\n\\n\\n\\n\\nCONTENTS\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Coming',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Ship.......7\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Love.....................15\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Marriage.................19\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Children.................21\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Giving...................23\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Eating',\n",
       " 'and',\n",
       " 'Drinking......27\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Work.....................31\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Joy',\n",
       " 'and',\n",
       " 'Sorrow...........33\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Houses...................37\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Clothes..................41\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Buying',\n",
       " 'and',\n",
       " 'Selling.......43\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment.....45\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Laws.....................51\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Freedom..................55\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Reason',\n",
       " 'and',\n",
       " 'Passion.......57\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pain.....................60\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Self-Knowledge...........62\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Teaching.................64\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Friendship...............66\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Talking..................68\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Time.....................70\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Good',\n",
       " 'and',\n",
       " 'Evil............72\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Prayer...................76\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pleasure.................79\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Beauty...................83\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Religion.................87\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Death....................90\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Farewell................92\\n\\n\\n\\n\\nTHE',\n",
       " 'PROPHET\\n\\n|Almustafa,',\n",
       " 'the',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own\\nday,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'city\\nof',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to\\nreturn',\n",
       " 'and',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'isle',\n",
       " 'of\\nhis',\n",
       " 'birth.\\n\\nAnd',\n",
       " 'in',\n",
       " 'the',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'the',\n",
       " 'seventh\\nday',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'the',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he\\nclimbed',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'the',\n",
       " 'city',\n",
       " 'walls\\nand',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'and',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his\\nship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'the',\n",
       " 'mist.\\n\\nThen',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung\\nopen,',\n",
       " 'and',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'the',\n",
       " 'sea.\\nAnd',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'the\\nsilences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.\\n\\n*****\\n\\nBut',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'the',\n",
       " 'hill,',\n",
       " 'a',\n",
       " 'sadness\\ncame',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his\\nheart:\\n\\nHow',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'without\\nsorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'a',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'the\\nspirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " '',\n",
       " 'the',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent\\nwithin',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'and',\n",
       " 'long',\n",
       " 'were',\n",
       " 'the\\nnights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'and',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart\\nfrom',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'and',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without\\nregret?\\n\\nToo',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I\\nscattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'and',\n",
       " 'too',\n",
       " 'many\\nare',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk\\nnaked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'cannot\\nwithdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'a',\n",
       " 'burden',\n",
       " 'and\\nan',\n",
       " 'ache.\\n\\nIt',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this\\nday,',\n",
       " 'but',\n",
       " 'a',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own\\nhands.\\n\\nNor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,\\nbut',\n",
       " 'a',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'and\\nwith',\n",
       " 'thirst.\\n\\n*****\\n\\nYet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.\\n\\nThe',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her\\ncalls',\n",
       " 'me,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.\\n\\nFor',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'the',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in\\nthe',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'and',\n",
       " 'crystallize\\nand',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mould.\\n\\nFain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is\\nhere.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?\\n\\nA',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'tongue',\n",
       " 'and\\n',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone\\nmust',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'the',\n",
       " 'ether.\\n\\nAnd',\n",
       " 'alone',\n",
       " 'and',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'the\\neagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'the',\n",
       " 'sun.\\n\\n*****\\n\\nNow',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the\\nhill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'sea,\\nand',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'the\\nharbour,',\n",
       " 'and',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'the',\n",
       " 'mariners,\\nthe',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.\\n\\nAnd',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'and',\n",
       " 'he\\nsaid:\\n\\nSons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of\\nthe',\n",
       " 'tides,\\n\\nHow',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.\\nAnd',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which\\nis',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.\\n\\nReady',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'and',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with\\nsails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'the',\n",
       " 'wind.\\n\\nOnly',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in\\nthis',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look\\ncast',\n",
       " 'backward,\\n\\nAnd',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'a\\nseafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " '',\n",
       " 'you,\\nvast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,\\n\\nWho',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'the\\nriver',\n",
       " 'and',\n",
       " 'the',\n",
       " 'stream,\\n\\nOnly',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream\\nmake,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,\\n\\nAnd',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'a\\nboundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'a',\n",
       " 'boundless',\n",
       " 'ocean.\\n\\n*****\\n\\nAnd',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    return x.split('\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\\ufeffThe'],\n",
       " ['Project'],\n",
       " ['Gutenberg'],\n",
       " ['EBook'],\n",
       " ['of'],\n",
       " ['The'],\n",
       " ['Prophet,'],\n",
       " ['by'],\n",
       " ['Kahlil'],\n",
       " ['Gibran', '', 'This']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_line = list(map(line_break, prophet_reference));\n",
    "prophet_line[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_flat = [y for x in prophet_line for y in x if y != ''];\n",
    "prophet_flat[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''    \n",
    "    word_list = ['and', 'the', 'a', 'an'];\n",
    "    return x not in word_list;    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat));\n",
    "prophet_filter[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Part 2\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    return x.lower() not in word_list \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No case sensitive: ['almost', 'no', 'restrictions', 'whatsoever.', 'You', 'may', 'copy', 'it,', 'give', 'it']\n",
      "---------------------------\n",
      "Case sensitive: ['no', 'restrictions', 'whatsoever.', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away']\n"
     ]
    }
   ],
   "source": [
    "prophet_filter_case = list(filter(word_filter_case, prophet_flat));\n",
    "print(\"No case sensitive:\", prophet_filter[30:40])\n",
    "print('---------------------------')\n",
    "print(\"Case sensitive:\", prophet_filter_case[30:40])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    return \"{} {}\".format(a,b);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffThe Project Gutenberg EBook of The Prophet, by Kahlil Gibran This eBook is for use of anyone anywhere in United States most other parts of world at no cost with almost no restrictions whatsoever. You may copy it, give it away or re-use it under terms of Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in United States, you'll have to check laws of country where you are located before using this ebook. Title: The Prophet Author: Kahlil Gibran Release Date: January 1, 2019 [EBook #58585] Last Updated: January 3, 2018 Language: English Character set encoding: UTF-8 *** START OF THIS PROJECT GUTENBERG EBOOK THE PROPHET *** Produced by David Widger from page images generously provided by Internet Archive Transcriber's Note: Page numbers, ie: are included in this utf-8 text file. For those wishing to use text file unencumbered with page numbers open or download Latin-1 file 58585-8.txt. THE PROPHET By Kahlil Gibran New York: Alfred A.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_string = reduce(concat_space, prophet_filter)\n",
    "prophet_string[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will load a dataset below and then write a function that will perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "# The dataset below contains information about pollution from PM2.5 particles in Beijing \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    return(x/24)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_hourly = pm25[['Iws','Is','Ir']].apply(hourly)\n",
    "pm25_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    return np.std(x) / (x.count() - 1);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_hourly_sd = pm25[['Iws','Is','Ir']].apply(sample_sd);\n",
    "pm25_hourly_sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
