{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# load the data\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], \n",
    "                 columns=data[\"feature_names\"])\n",
    "\n",
    "y = pd.DataFrame(data[\"target\"], \n",
    "                 columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE   DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.09  1.0  296.0     15.3   \n",
       "\n",
       "       B  LSTAT  MEDV  \n",
       "0  396.9   4.98  24.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                   random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# fit the train data\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# predict y_pred based on X_test values\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# predict the train\n",
    "y_pred_train = lm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def lm(x, y, njobs=1, normalize=True, fit_intercept=False):\n",
    "    # calling train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    # import the model\n",
    "    lm = LinearRegression(njobs, normalize)\n",
    "    # fit the train data\n",
    "    lm.fit(X_train, y_train)\n",
    "    # predict values\n",
    "    y_pred = lm.predict(X_test)\n",
    "    # ERRORS\n",
    "    # r2 score\n",
    "    r2 = round((r2_score(y_test, y_pred)*100),2)\n",
    "    # mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # mean_absolute_error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # create a dataframe\n",
    "    df_error = pd.DataFrame([r2, mse, mae])\n",
    "    df_error.index = ['r2', 'MSE', 'MAE']\n",
    "    return(df_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>61.180000</td>\n",
       "      <td>61.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>29.908872</td>\n",
       "      <td>29.908872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.694496</td>\n",
       "      <td>3.694496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model1     model2\n",
       "r2   61.180000  61.180000\n",
       "MSE  29.908872  29.908872\n",
       "MAE   3.694496   3.694496"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = lm(X_train, y_train, njobs=1, normalize=True, fit_intercept=False)\n",
    "m2 = lm(X_train, y_train, njobs=1000, normalize=False, fit_intercept=True)\n",
    "df_metrics = pd.concat([m1, m2], axis=1)\n",
    "df_metrics.columns = ['model1', 'model2']\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read R2 coefficient? \n",
    "* Determines how well the regression predictions approximate to the real data points\n",
    "> R2 score varies from 0 to 1: 0 is a poor fitting, and 1 the best fitting\n",
    "In other words:\n",
    ">> * 0% indicates that the model explains none of the variability of the response data around its mean.\n",
    ">> * 100% indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "Source('https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789207451814436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285831776605591"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.49542012244824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1130437468933985"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X2 = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y2 = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X2, y2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, \n",
    "                                                        test_size=0.2,\n",
    "                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next questions could be answered by aggregating the metrics into a single table with the following scores:\n",
    "> * accuracy_score\n",
    "> * balanced_accuracy_score\n",
    "> * precision_score\n",
    "> * recall_score\n",
    "> * f1_score\n",
    "\n",
    "* Let's create 3 models and compare their metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1\n",
    "# import the model without any hyperparameter\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "lr.fit(X_train2, y_train2)\n",
    "\n",
    "# predict the model with test values\n",
    "y_pred_lr = lr.predict(X_test2)\n",
    "\n",
    "# predict the model with train\n",
    "y_pred_lr_train = lr.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2\n",
    "# import the model with solver hyperparameter\n",
    "lr2 = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# fit the model\n",
    "lr2.fit(X_train2, y_train2)\n",
    "\n",
    "# predict the model with test values\n",
    "y_pred_lr2 = lr2.predict(X_test2)\n",
    "\n",
    "# predict the model with train\n",
    "y_pred_lr_train2 = lr2.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 3\n",
    "# import the model with solver and multi_class hyperparameter\n",
    "lr3 = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "# fit the model\n",
    "lr3.fit(X_train2, y_train2)\n",
    "\n",
    "# predict the model with test values\n",
    "y_pred_lr3 = lr3.predict(X_test2)\n",
    "\n",
    "# predict the model with train\n",
    "y_pred_lr_train2 = lr3.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def errors_log_func(y_test, y_pred):\n",
    "    # ERRORS\n",
    "    # accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # balanced accuracy\n",
    "    b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    # precision\n",
    "    precision_nome = precision_score(y_test, y_pred, average=None)\n",
    "    precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
    "    # recall\n",
    "    recall_none = recall_score(y_test, y_pred, average=None)\n",
    "    recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
    "    recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    # f1_score\n",
    "    f1_score_none = f1_score(y_test, y_pred, average=None)\n",
    "    f1_score_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    # concat the calculated metrics\n",
    "    df_error = pd.DataFrame([accuracy, b_accuracy, precision_nome, precision_micro, precision_macro, precision_weighted,\n",
    "                            recall_none, recall_weighted, recall_micro, recall_macro, f1_score_none, \n",
    "                             f1_score_weighted, f1_score_micro, f1_score_macro])\n",
    "    \n",
    "    df_error = df_error.T\n",
    "    df_error.columns = ['accuracy', 'balance_accuracy', 'precision_nome', 'precision_micro', 'precision_macro', 'precision_weighted',\n",
    "        'recall_none', 'recall_weighted', 'recall_micro', 'recall_macro', 'f1_score_none', \n",
    "        'f1_score_weighted', 'f1_score_micro', 'f1_score_macro']\n",
    "    df_error = df_error.T\n",
    "    return(df_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function and \n",
    "m1_log = errors_log_func(y_test2, y_pred_lr)\n",
    "m2_log = errors_log_func(y_test2, y_pred_lr2)\n",
    "m3_log = errors_log_func(y_test2, y_pred_lr3)\n",
    "\n",
    "# concat all the function results\n",
    "df_error_log = pd.concat([m1_log, m2_log, m3_log], axis=1)\n",
    "# rename columns\n",
    "df_error_log.columns = ['model1', 'model2_lbfgs', 'model3_lbfgs_multinomial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2_lbfgs</th>\n",
       "      <th>model3_lbfgs_multinomial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance_accuracy</th>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_nome</th>\n",
       "      <td>[1.0, 1.0, 0.5454545454545454]</td>\n",
       "      <td>[1.0, 1.0, 0.6]</td>\n",
       "      <td>[1.0, 1.0, 0.8571428571428571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_micro</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_macro</th>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_weighted</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_none</th>\n",
       "      <td>[1.0, 0.6153846153846154, 1.0]</td>\n",
       "      <td>[1.0, 0.6923076923076923, 1.0]</td>\n",
       "      <td>[1.0, 0.9230769230769231, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_weighted</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_micro</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_macro</th>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_none</th>\n",
       "      <td>[1.0, 0.761904761904762, 0.7058823529411764]</td>\n",
       "      <td>[1.0, 0.8181818181818181, 0.7499999999999999]</td>\n",
       "      <td>[1.0, 0.9600000000000001, 0.923076923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.838002</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.967282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.822596</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>0.961026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          model1  \\\n",
       "accuracy                                                0.833333   \n",
       "balance_accuracy                                        0.871795   \n",
       "precision_nome                    [1.0, 1.0, 0.5454545454545454]   \n",
       "precision_micro                                         0.833333   \n",
       "precision_macro                                         0.848485   \n",
       "precision_weighted                                      0.909091   \n",
       "recall_none                       [1.0, 0.6153846153846154, 1.0]   \n",
       "recall_weighted                                         0.833333   \n",
       "recall_micro                                            0.833333   \n",
       "recall_macro                                            0.871795   \n",
       "f1_score_none       [1.0, 0.761904761904762, 0.7058823529411764]   \n",
       "f1_score_weighted                                       0.838002   \n",
       "f1_score_micro                                          0.833333   \n",
       "f1_score_macro                                          0.822596   \n",
       "\n",
       "                                                     model2_lbfgs  \\\n",
       "accuracy                                                 0.866667   \n",
       "balance_accuracy                                         0.897436   \n",
       "precision_nome                                    [1.0, 1.0, 0.6]   \n",
       "precision_micro                                          0.866667   \n",
       "precision_macro                                          0.866667   \n",
       "precision_weighted                                           0.92   \n",
       "recall_none                        [1.0, 0.6923076923076923, 1.0]   \n",
       "recall_weighted                                          0.866667   \n",
       "recall_micro                                             0.866667   \n",
       "recall_macro                                             0.897436   \n",
       "f1_score_none       [1.0, 0.8181818181818181, 0.7499999999999999]   \n",
       "f1_score_weighted                                        0.871212   \n",
       "f1_score_micro                                           0.866667   \n",
       "f1_score_macro                                           0.856061   \n",
       "\n",
       "                                        model3_lbfgs_multinomial  \n",
       "accuracy                                                0.966667  \n",
       "balance_accuracy                                        0.974359  \n",
       "precision_nome                    [1.0, 1.0, 0.8571428571428571]  \n",
       "precision_micro                                         0.966667  \n",
       "precision_macro                                         0.952381  \n",
       "precision_weighted                                      0.971429  \n",
       "recall_none                       [1.0, 0.9230769230769231, 1.0]  \n",
       "recall_weighted                                         0.966667  \n",
       "recall_micro                                            0.966667  \n",
       "recall_macro                                            0.974359  \n",
       "f1_score_none       [1.0, 0.9600000000000001, 0.923076923076923]  \n",
       "f1_score_weighted                                       0.967282  \n",
       "f1_score_micro                                          0.966667  \n",
       "f1_score_macro                                          0.961026  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table metrics\n",
    "df_error_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test2, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train2, y_pred_lr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test2, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954954954954955"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train2, \n",
    "                        y_pred_lr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, y_pred_lr, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484848484848485"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, y_pred_lr, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, y_pred_lr, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.54545455])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test2, y_pred_lr, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.61538462, 1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test2, y_pred_lr, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.61538462, 1.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test2, y_pred_lr, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.76190476, 0.70588235])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test2, y_pred_lr, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.76190476, 0.70588235])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test2, y_pred_lr,average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test2, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.matshow(cnf_matrix, cmap='tab20')\n",
    "\n",
    "for x in range(0, 2):\n",
    "    for y in range(0, 2):\n",
    "        plt.text(x, y, cnf_matrix[x, y])\n",
    "        \n",
    "plt.ylabel('expected label')\n",
    "plt.xlabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix2 = confusion_matrix(y_test2, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.matshow(cnf_matrix, cmap='tab20')\n",
    "\n",
    "for x in range(0, 2):\n",
    "    for y in range(0, 2):\n",
    "        plt.text(x, y, cnf_matrix2[x, y])\n",
    "        \n",
    "plt.ylabel('expected label')\n",
    "plt.xlabel('predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
